{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. Load breast cancer dataset (**structured data**)\n",
        "\n",
        "For more details about the data: https://scikit-learn.org/1.5/modules/generated/sklearn.datasets.load_breast_cancer.html"
      ],
      "metadata": {
        "id": "t1I0ncvTh3x8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "my_data = load_breast_cancer()\n"
      ],
      "metadata": {
        "id": "QbVFGbTWiI1W"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Visualize the data\n",
        "\n",
        "- Only **5 points** for visualizing the data\n",
        "- Use TSNE algorithm: sklearn.manifold.TSNE\n",
        "- A good and simple code can be found here (they used PCA instead of TSNE): https://skp2707.medium.com/pca-on-cancer-dataset-4d7a97f5fdb8"
      ],
      "metadata": {
        "id": "LZgoZpwxXcuz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ],
      "metadata": {
        "id": "D3DKodjmYIBD"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Split **my_data** to train and test:\n",
        "\n",
        "- Define X_train, X_test, Y_train, Y_test\n",
        "- Choose **test_size** for splitting **my_data**\n",
        "- Use **train_test_split** (for details: https://scikit-learn.org/dev/modules/generated/sklearn.model_selection.train_test_split.html)"
      ],
      "metadata": {
        "id": "LpYvmEUWlf2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# X_train, X_test, Y_train, Y_test = train_test_split(...)\n",
        "X=my_data.data\n",
        "Y=my_data.target\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "V8CpCqnGmCg2"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "k0-2UMYej49I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Train **model_decision_tree**\n",
        "\n",
        "- Library: sklearn.tree.DecisionTreeClassifier\n",
        "- Data: X_train, Y_train\n",
        "- **Essential**: explore and optimize DecisionTreeClassifier options   "
      ],
      "metadata": {
        "id": "o1_cFF_cjIyK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# model_decision_tree = DecisionTreeClassifier(...)\n",
        "model_decision_tree = DecisionTreeClassifier( criterion='entropy',\n",
        "    max_depth=3,\n",
        "    min_samples_split=10,\n",
        "    min_samples_leaf=2,\n",
        "    random_state=42\n",
        "        )\n",
        "# model_decision_tree.fit(...)\n",
        "model_decision_tree.fit(X_train,Y_train)\n",
        "Y_pred_dt=model_decision_tree.predict(X_test)\n",
        "''"
      ],
      "metadata": {
        "id": "W8CWNt_2iZm4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b6476bd5-1f87-4fba-dd4d-fb8f1464c1ac"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Train model_random_forest\n",
        "- Library: sklearn.ensemble.RandomForestClassifier\n",
        "- Data: X_train, Y_train\n",
        "- **Essential**: explore and optimize RandomForestClassifier options"
      ],
      "metadata": {
        "id": "X__nmyElkPWs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# model_random_forest = RandomForestClassifier(...)\n",
        "model_random_forest = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    criterion='entropy',\n",
        "    max_depth=4,\n",
        "    min_samples_split=2,\n",
        "    min_samples_leaf=1,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "# model_random_forest.fit(...)a\n",
        "model_random_forest.fit(X_train,Y_train)\n",
        "Y_pred_rf=model_random_forest.predict(X_test)"
      ],
      "metadata": {
        "id": "6B4GKjlCkRdT"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Train model_adaboost\n",
        "\n",
        "- Library: sklearn.ensemble.AdaBoostClassifier\n",
        "- Data: X_train, Y_train\n",
        "- **Essential**: explore and optimize AdaBoostClassifier options"
      ],
      "metadata": {
        "id": "4qOTlMrDkSBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "# model_adaboost = AdaBoostClassifier(...)\n",
        "model_adaboost = AdaBoostClassifier(\n",
        "\n",
        "    n_estimators=50,\n",
        "    learning_rate=1.0,\n",
        "    algorithm='SAMME.R',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# model_adaboost.fit(...)\n",
        "model_adaboost.fit(X_train,Y_train)\n",
        "Y_pred = model_adaboost.predict(X_test)\n"
      ],
      "metadata": {
        "id": "Y5VGaDhJkYsL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1770be5b-33e3-4d7b-ab5d-f270325b3009"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Evaluate model_decision_tree, model_random_forest, model_adaboost\n",
        "\n",
        "- Library: sklearn.metrics\n",
        "- Data: X_test, Y_test\n",
        "- **Calculate** and **print** results of each classifier\n",
        "- **Choose** the decisive metric\n",
        "- **Compare** between the classifiers and declare the winner\n"
      ],
      "metadata": {
        "id": "0AdCG5Pfta5S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "def eval_model(metric, y_test, y_pred):\n",
        "    print(f\"--- {metric} Evaluation ---\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "    print(\"Precision:\", precision_score(y_test, y_pred))\n",
        "    print(\"Recall:\", recall_score(y_test, y_pred))\n",
        "    print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "    print(\"\\n\")\n",
        "\n",
        "\n",
        "y_pred_dt = model_decision_tree.predict(X_test)\n",
        "eval_model(\"Decision Tree\", Y_test, y_pred_dt)\n",
        "\n",
        "\n",
        "y_pred_rf = model_random_forest.predict(X_test)\n",
        "eval_model(\"Random Forest\", Y_test, y_pred_rf)\n",
        "\n",
        "\n",
        "y_pred_ab = model_adaboost.predict(X_test)\n",
        "eval_model(\"AdaBoost\", Y_test, y_pred_ab)\n",
        "\n",
        "\n",
        "f1_dt = f1_score(Y_test, y_pred_dt)\n",
        "f1_rf = f1_score(Y_test, y_pred_rf)\n",
        "f1_ab = f1_score(Y_test, y_pred_ab)\n",
        "\n",
        "f1_scores = {\"Decision Tree\": f1_dt, \"Random Forest\": f1_rf, \"AdaBoost\": f1_ab}\n",
        "winner = max(f1_scores, key=f1_scores.get)\n",
        "\n",
        "print(\"Decisive Metric: F1 Score\")\n",
        "print(\"Winner:\", winner)\n",
        "#"
      ],
      "metadata": {
        "id": "MkTXQR3mrBmM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a99d9a9-9e2c-453c-8200-d7e844f88a41"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Decision Tree Evaluation ---\n",
            "Accuracy: 0.9649122807017544\n",
            "Precision: 0.9466666666666667\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9726027397260274\n",
            "Confusion Matrix:\n",
            " [[39  4]\n",
            " [ 0 71]]\n",
            "\n",
            "\n",
            "--- Random Forest Evaluation ---\n",
            "Accuracy: 0.9649122807017544\n",
            "Precision: 0.958904109589041\n",
            "Recall: 0.9859154929577465\n",
            "F1 Score: 0.9722222222222222\n",
            "Confusion Matrix:\n",
            " [[40  3]\n",
            " [ 1 70]]\n",
            "\n",
            "\n",
            "--- AdaBoost Evaluation ---\n",
            "Accuracy: 0.9736842105263158\n",
            "Precision: 0.9722222222222222\n",
            "Recall: 0.9859154929577465\n",
            "F1 Score: 0.9790209790209791\n",
            "Confusion Matrix:\n",
            " [[41  2]\n",
            " [ 1 70]]\n",
            "\n",
            "\n",
            "Decisive Metric: F1 Score\n",
            "Winner: AdaBoost\n"
          ]
        }
      ]
    }
  ]
}